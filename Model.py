import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.neural_network import MLPRegressor
import matplotlib.pyplot as plt
import joblib



# H√†m hu·∫•n luy·ªán m√¥ h√¨nh MLP
def train_mlp_model(data):
    data.rename(columns={
        'Gi√° (T·ª∑)': 'Gi√°',
        'Di·ªán t√≠ch (M2)': 'Di·ªán t√≠ch'
    }, inplace=True)

    # Danh s√°ch c·ªôt s·ªë
    numeric_features = ['Di·ªán t√≠ch', 'Chi·ªÅu ngang', 'Chi·ªÅu d√†i', 'ƒê∆∞·ªùng tr∆∞·ªõc nh√†', 'S·ªë l·∫ßu', 'S·ªë ph√≤ng ng·ªß']
    # C·ªôt nh·ªã ph√¢n
    binary_cols = ['Ph√≤ng ƒÉn', 'Nh√† b·∫øp', 'S√¢n th∆∞·ª£ng', 'Ch·ªó ƒë·ªÉ xe h∆°i', 'Ch√≠nh ch·ªß']
    # C·ªôt ph√¢n lo·∫°i
    categorical_features = ['ƒê∆∞·ªùng', 'Ph∆∞·ªùng', 'Qu·∫≠n', 'Th√†nh ph·ªë', 'Lo·∫°i BDS', 'H∆∞·ªõng']

    # √âp ki·ªÉu numeric v√† ki·ªÉm tra l·ªói
    for col in numeric_features + binary_cols + ['Gi√°']:
        data[col] = pd.to_numeric(data[col], errors='coerce')

    # X·ª≠ l√Ω gi√° tr·ªã thi·∫øu ·ªü c·ªôt 'Gi√°'
    data = data.dropna(subset=['Gi√°'])

    # ƒêi·ªÅn gi√° tr·ªã thi·∫øu cho ph√¢n lo·∫°i
    data[categorical_features] = data[categorical_features].fillna('Unknown')


    # T·∫°o ƒë·∫∑c tr∆∞ng X v√† m·ª•c ti√™u y
    X = data[numeric_features + categorical_features + binary_cols]
    y = np.log1p(data['Gi√°'])  # log(1 + Gi√°)

    # T√°ch t·∫≠p train/test
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Pipeline ti·ªÅn x·ª≠ l√Ω
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', Pipeline([
                ('imputer', SimpleImputer(strategy='median')), # thay c√°c gi√° tr·ªã Nan v·ªÅ Median
                ('scaler', StandardScaler()) #Chu·∫©n h√≥a d·ªØ li·ªáu v·ªÅ d·∫°ng c√≥ trung b√¨nh = 0, ƒë·ªô l·ªách chu·∫©n = 1 ‚Üí M·ª•c ti√™u l√† gi√∫p m√¥ h√¨nh h·ªôi t·ª• t·ªët h∆°n khi d·ªØ li·ªáu ƒë·∫ßu v√†o ƒë·ªìng ƒë·ªÅu.
            ]), numeric_features + binary_cols),
            ('cat', Pipeline([
                ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')), # Nan replace with unkonw
                ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first')) # ch∆∞a c√≥ gi√° tr·ªã th√¨ b qun thay v√¨ b√°o l·ªói
            ]), categorical_features)
        ])


#multilayer perceptron
    model_pipeline = Pipeline([
        ('preprocessor', preprocessor),
        ('mlp', MLPRegressor(
            hidden_layer_sizes=(128, 64, 32),
            activation='relu',
            solver='adam',
            max_iter=1500,
            random_state=42
            #early_stopping=True,
            #validation_fraction=0.1
        ))
    ])

    # Hu·∫•n luy·ªán m√¥ h√¨nh
    model_pipeline.fit(X_train, y_train)

    # D·ª± ƒëo√°n v√† chuy·ªÉn l·∫°i d·∫°ng gi√° g·ªëc
    log_predictions = model_pipeline.predict(X_test)
    predictions = np.expm1(log_predictions)

    # ƒê√°nh gi√° m√¥ h√¨nh
    y_test_original = np.expm1(y_test)
    mse = mean_squared_error(y_test_original, predictions)
    r2 = r2_score(y_test_original, predictions)



    print("üìä M·ªôt s·ªë d·ª± ƒëo√°n m·∫´u:")
    results_df = pd.DataFrame({
        'Gi√° th·ª±c t·∫ø (T·ª∑)': y_test_original.values,
        'Gi√° d·ª± ƒëo√°n (T·ª∑)': predictions
    })
    print(results_df.head(100).to_string(index=False))


    print(f"\nüß† Mean Squared Error (MSE): {mse:.2f}")
    print(f"üß† R-squared (R¬≤): {r2:.2f}\n")
    # V·∫Ω bi·ªÉu ƒë·ªì so s√°nh
    plt.figure(figsize=(8, 5))
    plt.scatter(y_test_original, predictions, alpha=0.7)
    plt.plot([y_test_original.min(), y_test_original.max()], [y_test_original.min(), y_test_original.max()], 'r--')
    plt.xlabel("Gi√° th·ª±c t·∫ø (T·ª∑)")
    plt.ylabel("Gi√° d·ª± ƒëo√°n (T·ª∑)")
    plt.title("So s√°nh Gi√° th·ª±c t·∫ø vs D·ª± ƒëo√°n (MLP)")
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    return model_pipeline


# ƒê·ªçc file d·ªØ li·ªáu
data = pd.read_csv('F:/3.5 Years/First Year/Python/Mini_Linear/final_data_clean_1.csv')

# Hu·∫•n luy·ªán m√¥ h√¨nh
trained_model = train_mlp_model(data)
joblib.dump(trained_model, 'F:/3.5 Years/First Year/Python/Mini_Linear/trained_rf_model.pkl')
print("üíæ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 'trained_rf_model.pkl'")